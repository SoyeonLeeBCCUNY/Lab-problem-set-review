---
title: "Lab6 comparison extra credit"
author: "Soyeon Lee"
date: "3/30/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Concept 1: Understanding orthogonal contrasts

<iframe width="560" height="315" src="https://www.youtube.com/embed/egoVLWApFMU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


```{r}
knitr::include_graphics("imgs/LinearContrasts/LinearContrasts.004.jpeg")
```

The figure shows some group means that are different from the grand mean. The top right panel shows how each group mean can be considered as a unique source for each difference. The bottom three panels on the right show a set of three orthogonal contrasts, which is an alternative way of breaking down the sources of the differences. 

Here are a similar pattern of group means, along with the grand mean, deviations, and sum of squares.

```{r}

group_means <- c(4,3,10,11)
(grand_mean <- mean(group_means))
(differences <- group_means-grand_mean)
(squared_differences <- differences^2)
(sum_squares <- sum(squared_differences))

```

If all of the groups are different, and each of them have an independent influence on the grand mean, then we can think of each group mean as having it's own unique effect (represented as four different colored lines in the top right of panel above).

Even though there are four presumed influences, because we are estimating them on the basis of the grand mean, one degree of freedom is lost. So, three of the group means could be any number, but the last one would be fixed in order for the set to produce the specific grand mean here. 

When we define linear contrasts, we are defining the make-up of specific means in terms of combinations of the set of means. So, the default ANOVA assumption that each mean is unique, can be thought of itself as a very basic set of orthogonal contrasts.

If we enter the group names and means into a dataframe, and declare the IV as a factor, we can see the basic set of orthogonal contrasts.

```{r}
library(tibble)
fake_data <- tibble(IV = factor(c("A","B","C","D")),
                    DV = c(4,3,10,11))

contrasts(fake_data$IV)
```

Let's walk through this and answer some rhetorical questions. Our question for each group mean is, "how will we estimate this mean?". First of all, we assume that all of the group means are deviations from the grand mean. So each group mean will be expressed as the sum of the grand mean and a deviation.

Let's start with D. What values from the data will we use to estimate the mean of D? The values in the column for D show the contrast **weights**. We are saying we will take 100% of deviation for D (an 4), and 0% of the other means.

```{r}
contrasts(fake_data$IV)[,'D']

contrasts(fake_data$IV)[,'D'] * differences

# the formula for D
grand_mean + (1 * differences[4])
```

The same goes for C and B. We will estimate each of those means, with the grand mean and their unique deviations

```{r}
contrasts(fake_data$IV)

contrasts(fake_data$IV) * differences
```

So far if we say that each mean is the sum of the grand mean and the unique deviations from the grand mean, we get the original mean back for B, C, and D:

```{r}
grand_mean*contrasts(fake_data$IV) + contrasts(fake_data$IV) * differences
```

Notice that there is no contrast weight for A. This is the last mean left. Remember the degrees of freedom issue. We can define three of means in terms of the grand mean, but the last one will be fixed. There is only one value that A can be, in order for the grand mean to be 7.

```{r}
grand_mean

# A has to be four, if the others are 3, 10, and 11)
mean(c(4, 3, 10, 11))
```

### Other orthogonal contrasts

```{r}
knitr::include_graphics("imgs/LinearContrasts/LinearContrasts.004.jpeg")
```

Just to keep this picture close at hand, the previous section showed how the top right panel, showing the idea that each mean is a unique source, can be described in terms of linear contrasts.

The same set of means can be described by **any** set of orthogonal linear contrasts. For example, consider the set of three contrasts in the figure.

```{r}
c1 <- c(-1,-1,1,1)
c2 <- c(1,-1,0,0)
c3 <- c(0,0,-1,1)

my_contrasts <- cbind(c1,c2,c3)

contrasts(fake_data$IV) <- my_contrasts
contrasts(fake_data$IV)

# check they are orthogonal
cor(contrasts(fake_data$IV))

```

The formula from the textbook for computing Sums of Squares for contrasts is:

$\frac{S(\sum{C_a M_a})^2}{\sum{C_a^2}}$

If we compute the SSs for each contrast, we can see that they add up to the same total SS (50) from the example above. This will be true for any set of orthogonal linear contrasts.

```{r}
# multiple contrast weights by group means
contrasts(fake_data$IV) * group_means

# Find the sums for each column
colSums(contrasts(fake_data$IV) * group_means)

# Square the sums
colSums(contrasts(fake_data$IV) * group_means)^2

# Multiply by the sample size per group, say 5
1 * colSums(contrasts(fake_data$IV) * group_means)^2

# divide by the SS for the contrast weights
1 * ((colSums(contrasts(fake_data$IV) * group_means)^2)/ colSums(contrasts(fake_data$IV)^2))
```

